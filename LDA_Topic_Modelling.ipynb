{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sOaln6RLxOX"
   },
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdaVVtAiLxUP",
    "outputId": "c0633224-34a3-4f5c-cad8-69a9fbba06f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Dataset : (161297, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../Datasets/drugsComTrain_raw.tsv',sep='\\t')\n",
    "print(\"The Shape of the Dataset :\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDtIM901L0R-",
    "outputId": "b346d4ed-376b-435c-db1c-5b56f6e824f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/teja/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lxOiKc0cg_O",
    "outputId": "0ea20706-3ec1-4529-d347-9c535f9e03af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/teja/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qrqNp8E5ciTY"
   },
   "outputs": [],
   "source": [
    "drug_name = ['lexapro', 'zoloft', 'prozac', 'paxil', 'celexa', 'cymbalta', 'pristiq',\n",
    "             'effexor', 'bupropion', 'mirtazapine', 'trazodone', 'vilazodone',\n",
    "             'vortioxetine', 'trintellix', 'viibryd', 'wellbutrin', 'bupropion', \n",
    "             'wellbutrin', 'mg', 'xl', 'sr', 'budeprion', 'sedyrel', 'aplenzin',\n",
    "             'buproban', 'forfivo', 'oleptro', 'remeron', 'soltab', \n",
    "             'vortioxetine', 'viibryd', 'zyban', 'antidepress']\n",
    "condition_name = ['depression', 'anxiety', 'insomnia', 'pain']\n",
    "other = ['day', 'week', 'month', 'year', 'take', 'use', 'try', 'doctor', 'drug', 'pill',\n",
    "         'dose', 'first', 'ive', 'im', 'would', 'go', 'get', 'time', 'start', 'feel',\n",
    "         'work', 'feel', 'felt', 'make', 'help', 'like', 'give', 'really', 'still', 'even',\n",
    "         'well', 'also', 'one', 'much', 'also', 'back', 'thing', 'differ', 'dont',\n",
    "         'stop', 'two', 'med', 'medicin', 'medic', 'hour', 'think', 'thought', 'even',\n",
    "         'almost', 'many', 'say', 'ago', 'could', 'know', 'lot', 'come', 'last', 'put',\n",
    "         'see', 'havent', 'didnt', 'come']\n",
    "\n",
    "customized_stopwords = drug_name+other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ogsKf1yjclFt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 14:45:36.231611: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-25 14:45:36.234907: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-25 14:45:36.234920: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-25 14:45:37.267414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-25 14:45:37.267441: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-25 14:45:37.267454: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (teja): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Lemmatize with POS Tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "stemmed_stopwords = []\n",
    "'''\n",
    "for w in customized_stopwords:\n",
    "    stemmed_stopwords.append(SnowballStemmer('english').stem(lemmatizer.lemmatize(w, get_wordnet_pos(w))))\n",
    "'''\n",
    "\n",
    "for w in customized_stopwords:\n",
    "    stemmed_stopwords.append(SnowballStemmer('english').stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UrTPvMCoUIF",
    "outputId": "b8189a97-90e9-4579-dbfb-dd7390ee7764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lexapro',\n",
       " 'zoloft',\n",
       " 'prozac',\n",
       " 'paxil',\n",
       " 'celexa',\n",
       " 'cymbalta',\n",
       " 'pristiq',\n",
       " 'effexor',\n",
       " 'bupropion',\n",
       " 'mirtazapin',\n",
       " 'trazodon',\n",
       " 'vilazodon',\n",
       " 'vortioxetin',\n",
       " 'trintellix',\n",
       " 'viibryd',\n",
       " 'wellbutrin',\n",
       " 'bupropion',\n",
       " 'wellbutrin',\n",
       " 'mg',\n",
       " 'xl',\n",
       " 'sr',\n",
       " 'budeprion',\n",
       " 'sedyrel',\n",
       " 'aplenzin',\n",
       " 'buproban',\n",
       " 'forfivo',\n",
       " 'oleptro',\n",
       " 'remeron',\n",
       " 'soltab',\n",
       " 'vortioxetin',\n",
       " 'viibryd',\n",
       " 'zyban',\n",
       " 'antidepress',\n",
       " 'day',\n",
       " 'week',\n",
       " 'month',\n",
       " 'year',\n",
       " 'take',\n",
       " 'use',\n",
       " 'tri',\n",
       " 'doctor',\n",
       " 'drug',\n",
       " 'pill',\n",
       " 'dose',\n",
       " 'first',\n",
       " 'ive',\n",
       " 'im',\n",
       " 'would',\n",
       " 'go',\n",
       " 'get',\n",
       " 'time',\n",
       " 'start',\n",
       " 'feel',\n",
       " 'work',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'make',\n",
       " 'help',\n",
       " 'like',\n",
       " 'give',\n",
       " 'realli',\n",
       " 'still',\n",
       " 'even',\n",
       " 'well',\n",
       " 'also',\n",
       " 'one',\n",
       " 'much',\n",
       " 'also',\n",
       " 'back',\n",
       " 'thing',\n",
       " 'differ',\n",
       " 'dont',\n",
       " 'stop',\n",
       " 'two',\n",
       " 'med',\n",
       " 'medicin',\n",
       " 'medic',\n",
       " 'hour',\n",
       " 'think',\n",
       " 'thought',\n",
       " 'even',\n",
       " 'almost',\n",
       " 'mani',\n",
       " 'say',\n",
       " 'ago',\n",
       " 'could',\n",
       " 'know',\n",
       " 'lot',\n",
       " 'come',\n",
       " 'last',\n",
       " 'put',\n",
       " 'see',\n",
       " 'havent',\n",
       " 'didnt',\n",
       " 'come']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyCT3X7QcoOZ",
    "outputId": "fcce29ea-9db1-404c-c8b3-bd63d0c24113"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/teja/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-FGJH1cdhe2",
    "outputId": "c92550ce-0de8-4fc6-9d37-6ba68752f516"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/teja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osVkbDARcpVV"
   },
   "outputs": [],
   "source": [
    "import string \n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# delete all the records where Condition or rating is Missing\n",
    "data = data.dropna()\n",
    "\n",
    "# First remove Punctuations from the Reviews\n",
    "def punctuation_removal(messy_str):\n",
    "    clean_list = [char for char in messy_str if char not in string.punctuation]\n",
    "    clean_str = ''.join(clean_list)\n",
    "    return clean_str\n",
    "data['review'] = data['review'].apply(punctuation_removal)\n",
    "\n",
    "## remove special symbol\n",
    "def rm_sym(df):\n",
    "    df['review'] = df['review'].str.replace(\"&#039;\",'\\'')\n",
    "    df['review'].head()\n",
    "    return df\n",
    "data = rm_sym(data)\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"\n",
    "    This function normalizes whitespaces, removing duplicates.\n",
    "    \"\"\"\n",
    "    corrected = str(text)\n",
    "    corrected = re.sub(r\"//t\",r\"\\t\", corrected)\n",
    "    corrected = re.sub(r\"( )\\1+\",r\"\\1\", corrected)\n",
    "    corrected = re.sub(r\"(\\n)\\1+\",r\"\\1\", corrected)\n",
    "    corrected = re.sub(r\"(\\r)\\1+\",r\"\\1\", corrected)\n",
    "    corrected = re.sub(r\"(\\t)\\1+\",r\"\\1\", corrected)\n",
    "    return corrected.strip(\" \")\n",
    "\n",
    "#data['review']=data['review'].apply(lambda x: normalize whitespace(x))\n",
    "\n",
    "def tokenize(text):\n",
    "    split=re.split(\"\\W+\",text)\n",
    "    split=split[1:-1]\n",
    "    return split\n",
    "data['review_list']=data['review'].apply(lambda x: tokenize(x.lower()))\n",
    "#data['review_list'].head()\n",
    "\n",
    "def drop_numbers(list_text):\n",
    "    list_text_new = []\n",
    "    for i in list_text:\n",
    "        if not re.search('\\d', i):\n",
    "            list_text_new.append(i)\n",
    "    return ' '.join(list_text_new)\n",
    "data['review']=data['review_list'].apply(lambda x: drop_numbers(x))\n",
    "data['review_list']=data['review'].apply(lambda x: tokenize(x))\n",
    "\n",
    "def lemmatize(word_list):\n",
    "    lemmatized = []\n",
    "    for w in word_list:\n",
    "        lemmatized.append(lemmatizer.lemmatize(w, get_wordnet_pos(w)))\n",
    "    return lemmatized\n",
    "\n",
    "data['review_list']=data['review_list'].apply(lambda x: lemmatize(x))\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "data['review_list'] = data['review_list'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "data['review_list'] = data['review_list'].apply(lambda x: stem_tokens(x, stemmer=stemmer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sZ2CCzEcuRF"
   },
   "outputs": [],
   "source": [
    "def combine(list_text):\n",
    "    list_text_new = []\n",
    "    for i in list_text:\n",
    "        list_text_new.append(i)\n",
    "    return ' '.join(list_text_new)\n",
    "data['review']=data['review_list'].apply(lambda x: combine(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2Sy4-8Dcw1G"
   },
   "outputs": [],
   "source": [
    "def remove_customized_stopwords(text):\n",
    "    text=[word for word in text if word not in stemmed_stopwords]\n",
    "    return text\n",
    "\n",
    "data['review_list_new'] = data['review_list'].apply(lambda x: remove_customized_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xju7JpRqczgz",
    "outputId": "fec467d5-ca8f-4d44-f3cf-90fb5c5bd757"
   },
   "outputs": [],
   "source": [
    "data['review_new']=data['review_list_new'].apply(lambda x: combine(x))\n",
    "data['review_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqiEA3R1c4hq"
   },
   "outputs": [],
   "source": [
    "# transform the ratings to three categories: positive, neutral and negative\n",
    "def transform_rating(df):\n",
    "    df['sentiment'] = ''\n",
    "    df.loc[df['rating'] >= 7,'sentiment'] = 'positive'\n",
    "    df.loc[df['rating'] <= 4,'sentiment'] = 'negative'\n",
    "    df.loc[(df['rating'] > 4) & (df['rating'] < 7),'sentiment'] = 'neutral'\n",
    "    return df\n",
    "data = transform_rating(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPC4u_ySdXix"
   },
   "outputs": [],
   "source": [
    "# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWz9AbmMdeaM",
    "outputId": "b0919743-d868-42fd-a249-b878ed0e4964"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_data = count_vectorizer.fit_transform(data[data.sentiment=='positive'].review_new)\n",
    "\n",
    "number_topics = 3\n",
    "number_words = 8\n",
    "\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1, random_state=1)\n",
    "lda.fit(count_data)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found in postive reviews via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeYmwQ1XeL56",
    "outputId": "f77d32d8-fc51-4f44-bc03-7c4d9b386e3f"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_data = count_vectorizer.fit_transform(data[data.sentiment=='negative'].review_new)\n",
    "\n",
    "number_topics = 3\n",
    "number_words = 8\n",
    "\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1, random_state=1)\n",
    "lda.fit(count_data)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found in postive reviews via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAI-8Du_eOxD",
    "outputId": "e12c8185-b599-4d6b-d662-47e4801c0645"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_data = count_vectorizer.fit_transform(data[data.sentiment=='neutral'].review_new)\n",
    "\n",
    "number_topics = 3\n",
    "number_words = 8\n",
    "\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1, random_state=1)\n",
    "lda.fit(count_data)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found in postive reviews via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oziKWKrH_XQ6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWUgvObmhFAP",
    "outputId": "3e2ca757-11db-475b-d53d-90030d516a00"
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data['review_list_new'])\n",
    "# Create Corpus\n",
    "texts = data['review_list_new']\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwoOOaGvppF7"
   },
   "source": [
    "### number of topic=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbjgDus-pdP4",
    "outputId": "57f0b80c-e8b0-4f78-a1dc-f28c9d1836da"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_HwmwFapg2S",
    "outputId": "f4b0ad04-d69d-4b95-80e4-679c9214fc38"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZSI9J5Apg4X",
    "outputId": "42652490-aa68-42ba-8002-b68ee6e05a67"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "wo9xaj0Spg7B",
    "outputId": "75736671-17d5-41f4-fc1d-fd0c0ef209bc"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tdjybD7pFBu"
   },
   "source": [
    "### number of topic=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoHC5P_KpDZA",
    "outputId": "31e3e272-5c33-4246-bb76-cefcd315842c"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f990VebgpJyq",
    "outputId": "5d5c7c6b-a9b4-43e3-ff67-1ff565ee1abc"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvOsa9MQpKGd",
    "outputId": "2d02b448-4ca3-4160-f1bc-908b90d1d20e"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "ZTkAXrg8pKJB",
    "outputId": "1e3b5b4d-2d41-41c2-d02e-87008172b162"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEQb5HQCoXnu"
   },
   "source": [
    "### number of topic=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wkZCrICl-k0",
    "outputId": "e386864c-0622-4360-9c60-d4f2cf105c7e"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rX8kZWz2mArb",
    "outputId": "7597cb17-e99f-4c79-c9f8-d19c80945d9a"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tk-4oICmAyV",
    "outputId": "b526ec67-de15-4b79-eb11-38b416de1230"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "uv707nb1orKd",
    "outputId": "83eabfc3-308d-4589-f966-88d485de62f6"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bk7rhrGzoTSb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpomt1mrmXVH",
    "outputId": "4486d5f8-c8ab-4a32-847f-83b0a962d383"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=6, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzjGFzrpmXXm",
    "outputId": "2968e315-2a17-4ce3-9ae7-f954f1ff4502"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V68T6GC2mXZ4",
    "outputId": "23d3f025-9400-4d93-9889-6c3052ba84f1"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2Nst_O-mgck",
    "outputId": "bbe05f18-5ed2-40af-c63f-35387ed89f55"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoHlELJsmuSX",
    "outputId": "4e11a3ec-665f-482e-deb5-6511f1c4f4f3"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQoBQR1omuU7",
    "outputId": "ea800bba-e372-4eb8-f208-62a6a6f8af43"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qnlm-D36muXz",
    "outputId": "ec42386f-b651-4bad-a4be-5a1cccd9fccf"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2ydjRzznIWx",
    "outputId": "9487543f-5462-46c4-dcd8-753babd248d0"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0QetTTMnIZH",
    "outputId": "eed2d890-1e90-460f-e466-a9c634b89d1b"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fskt5r6TnTwj",
    "outputId": "60778f1c-8ee5-4e8c-e94b-0efc8451072e"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=9, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfCJtKkKnTy1",
    "outputId": "c3555355-d360-418c-b321-4d7a2e802690"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wCW2QI9nT1R",
    "outputId": "a30d97a1-7e21-4a34-ad03-be96125aad8d"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVi7ZlLing5L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMtTDnqmmA6e"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOtapHMajliE",
    "outputId": "16251cf1-bcd9-46bd-f6a7-2d84966fc563"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42WKssYikWWW",
    "outputId": "6f045885-f6d9-4809-b834-a9b0e0ed4709"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHzXNQaCkaju",
    "outputId": "bd990718-13ae-46bd-ad05-427d5888bb7a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "U3rN2g2mjzQi",
    "outputId": "9fb9fc1d-286f-4c85-f2b3-d3625164f59f"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71bl3jLAolfR"
   },
   "source": [
    "### number of topic=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldVWPIrFfUoh"
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jFEM9OQfdFJ",
    "outputId": "aeea2435-0a19-4d6a-c3e1-63c9e8248bac"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aba6IUYUf9Ee"
   },
   "source": [
    "Topic 0 is a represented as _0.016“car” + 0.014“power” + 0.010“light” + 0.009“drive” + 0.007“mount” + 0.007“controller” + 0.007“cool” + 0.007“engine” + 0.007“back” + ‘0.006“turn”.\n",
    "\n",
    "It means the top 10 keywords that contribute to this topic are: ‘car’, ‘power’, ‘light’.. and so on and the weight of ‘car’ on topic 0 is 0.016.\n",
    "\n",
    "The weights reflect how important a keyword is to that topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uaQOCjXf3xN"
   },
   "source": [
    "Compute Model Perplexity and Coherence Score\n",
    "\n",
    "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. In my experience, topic coherence score, in particular, has been more helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mV1qcVDUf6tE",
    "outputId": "a0c411fb-3e26-460a-c0b1-fe8ec481a4a9"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "id": "-ISw9zK1gFey",
    "outputId": "8f858c48-a378-4d0f-aaed-23242f0cbeca"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsCtXP_JWzqJ",
    "outputId": "ef009d83-0027-4308-9f82-671015ca6b90"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDqTqZDZcQjS",
    "outputId": "3b299886-af1c-42d7-8529-a2f5a81a80fc"
   },
   "outputs": [],
   "source": [
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "id": "SmGSnGJnA65I",
    "outputId": "c1f90841-24bc-41a2-fbe2-e0d37228b039"
   },
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "mallet_path = '/content/drive/My Drive/mallet-2.0.8/bin/mallet' \n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuHW9IMiUhxd"
   },
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZ6_k_XUWWTk"
   },
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data['review_list_new'], start=2, limit=40, step=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcDBvaYVA9x9"
   },
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxFBq9oKBCLd"
   },
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-46C1Dg1wCx",
    "outputId": "4028a09f-5a96-4797-9d53-825cd36cfd74"
   },
   "outputs": [],
   "source": [
    "data[data['sentiment']=='positive'].review_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3oEMgkDraR7",
    "outputId": "0531b787-0a5d-422c-f9f7-3f66bbeb59c7"
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word_p = corpora.Dictionary(data[data['sentiment']=='positive'].review_list_new)\n",
    "# Create Corpus\n",
    "texts_p = data[data['sentiment']=='positive'].review_list_new\n",
    "# Term Document Frequency\n",
    "corpus_p = [id2word_p.doc2bow(text) for text in texts_p]\n",
    "# View\n",
    "print(corpus_p[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oZClGKNrcYy",
    "outputId": "f69bedb7-44fb-4ac5-bc53-8bc2cb23ce1c"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word_n = corpora.Dictionary(data[data['sentiment']=='negative'].review_list_new)\n",
    "# Create Corpus\n",
    "texts_n = data[data['sentiment']=='negative'].review_list_new\n",
    "# Term Document Frequency\n",
    "corpus_n = [id2word_n.doc2bow(text) for text in texts_n]\n",
    "# View\n",
    "print(corpus_n[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWNZForykZJc"
   },
   "source": [
    "### number of topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHgPl8H0h4A4",
    "outputId": "8347434d-5709-4335-fbe5-2baa15a29135"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "kOA_J4zbiMRP",
    "outputId": "dc1d06a5-26c8-4a61-db4a-17016bd6828a"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKadPLLGk3kG"
   },
   "source": [
    "### number of topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxPnTz0Lk3CE",
    "outputId": "d58bacf0-f70d-4957-df81-ca192d4050c2"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 2\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "Ssn2BDZrk82C",
    "outputId": "c1b21e47-ac4c-4eba-dfac-afc56f27fb71"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYEHbLDOk-Nx"
   },
   "source": [
    "### number of topics = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUE76R4dk_1C",
    "outputId": "9043539c-8467-49d7-fa2f-84b2da840c9a"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 3\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "HYrEgzXck_3R",
    "outputId": "dc9a82ed-89c7-4a2d-e630-70f30a23c2d1"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPaUbpXGrJJ_",
    "outputId": "84d8750d-3864-4abf-ca07-07dd219433c5"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 3\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus_p,\n",
    "                                       id2word=id2word_p,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "m0emtU1FsO7Q",
    "outputId": "c9666002-8640-4ca7-d0c8-1e9320775993"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus_p, id2word_p)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oG_HQB_32iiG",
    "outputId": "b98823e2-ca66-4072-e2ba-c168a262ba27"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 3\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus_n,\n",
    "                                       id2word=id2word_n,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "7xEXHl_p3DqI",
    "outputId": "d7ea553c-63fc-4830-da58-2c951fa5f6f3"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus_n, id2word_n)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRFYtZUl2oIo"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus_p, id2word_p)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWsVvGP3kdLN"
   },
   "source": [
    "### number of topics = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZGTKMzvkd0C",
    "outputId": "a78fe6be-1eb2-4c39-e140-98911cdaebc0"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 4\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "xrlAAVGFhzTi",
    "outputId": "a7e4a4df-ef6e-4194-9fdd-d445eaf38acd"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GPEDuBrlOVR"
   },
   "source": [
    "### number of topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aPTMM8TlRPO",
    "outputId": "976bdbae-7e59-4582-dcaa-480e208ac9f3"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 5\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "aUM8kZpLlRRp",
    "outputId": "00bf3254-6b20-4208-809a-edb57bedbb53"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwvnQ5nRq1XJ"
   },
   "source": [
    "### number of topics = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2YsK1M1q0BY",
    "outputId": "eb0be607-191a-4c17-fe98-11c2f5b73739"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "# number of topics\n",
    "num_topics = 6\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "agSbgKX-q49W",
    "outputId": "d2fa9ff9-f2c0-453e-b3ad-625b52b7ca65"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = './results/ldavis_prepared_'+str(num_topics)\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LDA Topic Modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
